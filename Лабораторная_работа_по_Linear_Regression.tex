\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\usepackage[T2A]{ fontenc }
\usepackage{ geometry }
\usepackage{ amssymb }
\usepackage{ dsfont }
\usepackage{ mdframed }
\usepackage{ amssymb }
\usepackage{ amsmath }
\usepackage{ wrapfig }
\usepackage{ hyperref }
\usepackage{ multirow }
\usepackage{ rotating }
\usepackage{ cleveref }
\usepackage{ subcaption }
\usepackage{ wrapfig }
\usepackage{ caption }

\geometry{
 a4paper,
 total={170mm,257mm},
 left=30mm,
 right=30mm,
 top=15mm,
}

\newmdenv[
  topline=false,
  bottomline=false,
  rightline=false,
  skipabove=\topsep,
  skipbelow=\topsep
]{leftrule}


\title{Лабораторная работа по Linear-Regression}
\author{Федоров Артем Максимович}
\date{317 группа, Ноябрь 2023}

\begin{document}

\maketitle

\section{Введение}
    Решение проблемы классификации объектов на конечное, заранее определенное число классов является классической задачей, решаемой методами машинного обучения. Такой класс задач подразумевает под собой нахождение алгоритма, закона, что наиболее точно определял бы зависимость между объектом с признаками и соответствующего класса.

    На практике, редко удается построить такое решение, что могло бы достоверно точно определять данную зависимость, что необязательно должно следовать из неидеальности применяемых моделей, но вполне может появиться и ввиду зашумленности данных, неидеальности системы классов и простой недообученности модели по причине отсутствия достаточного размера или смещенности обучающей выборки. Потому умение модели вместо одной лишь классификации оценивать и вероятность для каждого объекта быть причисленным к тому или иному классу является крайне важной и очень удобной на практике особенностью алгоритмов. В классе линейных моделей такой характеристикой, как предсказание вероятностей, обладает Логистическая регрессия \textbf{(Ligistic-Regression)}

    Одной из сфер применения машинного обучения, где повсеместно возникают задачи классификации, является раздел задач распознавания естественного языка (\textbf{NLP} - \textbf{N}atural \textbf{L}anguage \textbf{P}roccessing), в рамках возможных проблем которого могут встречаться задачи распознавания тематик научных документов, ценностной направленности текстов, поляризации мнений авторов, определения эмоциональной окраски текстов и так далее.

    Данный отчет стремится подвести итог экспериментам, проводимых в рамках изучения Логистической регрессии и ее работы в рамках задачи по категоризации человеческой речи с применением градиентных методов оптимизации.

\section{Начальные данные}
    Задачи \textbf{NLP}, как задачи построения интерфейса взаимодействия человека с компьютером, сильно зависят от представления первоначальных данных в обрабатываемый компьютером код. Потому рассматриваемая задача бинарной классификации текстов и ее итоговое решение нераздельно связаны с обработкой классифицируемых объектов. Важной задачей является правильно интерпретировать данные и построить на них оптимальное решение. 

    \subsection{Данные задачи}

    В задании рассматривается набор текстовых комментариев, собранных в интернете и размеченных на два класса соответственно: "комментарий не токсичный" и "комментарий токсичный". В дальнейшем множеством классов обозначается $\mathcal{Y}=\{-1, 1\}$, где положительный класс — обозначение токсичности комментария. Тогда естественно построить объект $\mathfrak{U}^{\ae}$ как множество любых символьных цепочек произвольной длины меньшей чем константа $\ae$ (условие на конечность), в дальнейшем именуемых \textbf{текстами}, приходящими на вход алгоритму. Пусть $\hat{\mathfrak{N}}^{\ae}$ есть конечное множество объектов из $\mathfrak{U}^{\ae}$, для которого определен оператор перевода $\mathcal{V}: \hat{\mathfrak{N}}^{\ae} \rightarrow \mathcal{X} \equiv \mathds{R}^{q \times l}$, осуществляющий отображение каждого объекта-строки из множества мощности $l$ в пространство вещественных векторов размерности $q$, где $l=|\hat{\mathfrak{N}}^{\ae}|$. Тем самым получен способ построения эмбеддингов (\textbf{embedding}) в признаковом пространстве $\mathds{R}^q$. 

    \subsection{Теоретический фундамент}

    После построения оператора перевода и получения эмбеддингов текстов, задача становится решаемой стандартными средствами машинного обучения. Будем считать, что такое представление верно и отражает каждый из объектов наиболее точно, а потому от представления начальных текстовых комментариев как $u_i \in \mathfrak{U}^{\ae}$ перейдем к преставлению этих объектов их эмбедингами из $\mathcal{X}$. На декартовом произведении $[\mathds{R}^q, \mathcal{Y}]$ определена операция бинарного соответствия $\sim$: будем считать, что $x \sim y$, где $x \in \mathcal{X}$ и $ y \in \mathcal{Y} $ тогда и только тогда, когда объекту $x$ поставлен в соответсвие класс $y$. Тогда построим стохастическую модель задачи, при которой каждый объект порождает дискретное вероятностное распределение на множестве $\mathcal{Y}$ как:

    \begin{center}
        \begin{tabular}{ c|c|c } 
             $x \sim y$ & $x \sim -1$ & $x \sim 1$ \\
             \hline
             $P(x \sim y)$ & $P(x \sim -1)$ & $P(x \sim 1)$\\
        \end{tabular}
    \end{center}
    
    \noindent Такое распределение является Бернулиевским. Пусть $X^l$ — выборка эмбеддингов мощности $l$ из пространства $\mathcal{X}$. Для такого распределения построим оценку максимального правдоподобия по выборке $X^{l}$ с соответственным вектором $y = \{y_i: x_i \sim y_i\}$ и вектором параметров $w \in \mathds{R}^{q + 1}$ и проведем оптимизацию по параметру $w$

    \begin{leftrule}
        Здесь и далее для простоты выкладок будем считать вектор $w \in \mathds{R}^{q + 1}$, как вектор, состоящий из двух частей:
            \begin{itemize}
                \item $\hat{w} \in \mathds{R}^q$ вектор весов соответственных признаков
                \item $w_0 \in \mathds{R}$ bias линейной регрессии
            \end{itemize}
    \end{leftrule}

    $$\hat{L}(X^l, y; w) = \prod_{i=1}^{l}{(P(x_i \sim -1 | w))^{[y_i = -1]} • (P(x_i \sim 1 | w))^{[y_i = 1]}} \longrightarrow \substack{max \\ w \in \mathds{R}^{q + 1}}$$

    Такая постановка оптимизационной задачи ввиду монотонности функции логарифма эквивалентна:
    
    $$L(X^l, y; w) = -\frac{1}{l}\sum_{i=1}^{l}{[y_i = -1]\ln{P(x_i \sim -1 | w)} + [y_i = 1]\ln{P(x_i \sim 1 | w)}} \longrightarrow \substack{min \\ w \in \mathds{R}^{q + 1}}$$


    Остается вопрос о том, как высчитывать вероятность каждого класса быть причисленным соответственному объекту при фиксированном $w$. Выбираем приближение вероятности функцией сигмоидой: $P(x_i \sim 1) = \sigma(x_i, w) = \sigma(M_i) = \frac{1}{1 + e^{-M_i}}$, где $M_i=\left\langle \hat{w}, x_i\right\rangle - w_0$. Алгоритм, решающий поставленную задачу, называется Логистической регрессией, а саму задачу оптимизации, приняв во внимание соотношение $1 - \sigma(M_i) = \sigma(-M_i)$, можно переписать в виде: 

    $$L(X^l, y; w) = \frac{1}{l}\sum_{i=1}^{l}{\ln(1+exp\{-y_i\left\langle w, x_i \right\rangle - w_0\})} \longrightarrow \substack{min \\ w \in \mathds{R}^{q + 1}}$$

    \subsubsection{Нахождение градиента}
        
        Для реализации градиентного алгоритма численного решения поставленной оптимизационной задачи требуется знание производной от функции эмпирического риска $L(X^l, y; w)$. 
        
    \begin{align*}
        & d(L(X^l, y; w))=\frac{1}{l}\sum^{l}_{i=1}{d(\ln(1+exp\{-y_i\left\langle \hat{w}, x_i \right\rangle -w_0\}))} & & & & & & & & & & & & & & & & & & & &  \\
        & d(L(X^l, y; w))=-\frac{1}{l}\sum^{l}_{i=1}\frac{e^{-M_i}}{1+e^{-M_i}}d(y_i \left\langle \hat{w}, x_i \right\rangle -w_0) & \\
        & d(L(X^l, y; w))=-\frac{1}{l}\sum^{l}_{i=1}\frac{e^{-M_i}}{1+e^{-M_i}}y_i \left\langle d\hat{w}, x_i \right\rangle & \\
        & d(L(X^l, y; w))= \left\langle dw, -\frac{1}{l}\sum^{l}_{i=1}\frac{e^{-M_i}}{1+e^{-M_i}}y_ix_i \right\rangle &
    \end{align*}

        \noindent Из чего следует явный вид градиента функции:
    \begin{align*}
        & \Longrightarrow \nabla L(X^l, y; w) = -\frac{1}{l}\sum^{l}_{i=1}\frac{e^{-M_i}}{1+e^{-M_i}}y_ix_i 
        & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & &
    \end{align*}

    \subsubsection{Мультиномиальная логистическая регрессия}

        Пусть теперь стоит задача мультиклассовой классификации. В таком случае множество классов задачи представимо в виде $\tilde{\mathcal{Y}}=\{1, 2, 3, ..., m\}$. В соответствии с бинарной задачей классификации, логично положить стохастическую модель в которой бинарное отношение $\sim$ определено на декартовом произведении $[\mathcal{X} \times \hat{\mathcal{Y}}]$, а каждый объект из $\mathcal{X}$ порождает дискретное вероятностное распределение вида:
    \begin{center}
        \begin{tabular}{ c|c|c|c } 
             $x \sim y$ & $x \sim 1$ & ... & $x \sim m$ \\
             \hline
             $P(x \sim y)$ & $P(x \sim -1)$ & ... & $P(x \sim m)$\\
        \end{tabular}
    \end{center}
        
        \noindent Оценка максимального правдоподобия и соответсвующая задачи оптимизации примут вид:

        $$\hat{L}(X^l, y; W) = \prod_{i=1}^{l}{\prod_{j=1}^{m}(P(x_i \sim j | w_j))^{[y_i = j]}} \longrightarrow \substack{max \\ w \in \mathds{R}^{q + 1 \times m}}$$

    \begin{leftrule}
        Заметим, что в общем случае веса для каждого из классов нельзя считать одинаковыми, а потому рассматривается не вектор весов, а матрица $W \in \mathds{R}^{m \times (q + 1)}$, из чего выходит, что функция $\sigma(x_i; w_j)$ больше не может считаться функцией оценки вероятности, так как не выполняется условие нормировки. Для этого используется подход \textbf{Soft-Max}, для которого вероятность каждого класса для объекта представима в виде: $P(x \sim j) = \frac{e^{z_j}}{\sum_{k=1}^{m}{e^{z_k}}}$, где $z_i = \left\langle w_j, x \right\rangle + w_{0j}$
    \end{leftrule}

        Запишем классическое представление оптимизационной задачи для мультиномиальной логистической регрессии:

        \begin{aligned}
            & L(X^l, y; W)=-\frac{1}{l}\sum_{i=1}^l \sum_{j=1}^k \left[y_i=j\right] \ln \left(1+\exp \left(-\left\langle w_j, x_i\right\rangle\right)\right) \\ & 
            \nabla_{w_k} L(X^l, y; W)=\frac{1}{l}\sum_{i=1}^l \left[y_i=k\right] \frac{\exp \left(-\left\langle w_k, x_i\right\rangle\right)}{1+\exp \left(-\left\langle w_k, x_i\right\rangle\right)} x_i=\frac{1}{l}\sum_{i=1}^l {\left[y_i=k\right] \left(1-\sigma\left(\left\langle w_k, x_i\right\rangle\right)\right) x_i}
        \end{aligned}

    \subsubsection{Сведение мультиномиальной Логистической регрессии к бинарной}

    Пусть $m=2$, $\mathcal{Y}=\{1, 2\}$. Таким образом задача вновь сводится к максимизации оценки максимального правдоподобия:
    
    $$\hat{L}(X^l, y; w) = \prod_{i=1}^{l}{\prod_{j=1}^{2}(P(x_i \sim j | w_j))^{[y_i = j]}}=
    \prod_{i=1}^{l}{P(x_i \sim 1 | w_1))^{[y_i = 1]}•P(x_i \sim 2 | w_2))^{[y_i = 2]}}
    \longrightarrow \substack{max \\ W \in \mathds{R}^{q + 1 \times 2}}$$

    Положив, $z_{ij}=<w_j, x_i> + w_{0j}$ получим запись для оценки вероятности первого класса для $i$ объекта: 
    $$P(x_i \sim 1 | W) = \frac{e^{z_{i1}}}{e^{z_{i1}} + e^{z_{i2}}} = 1 - \frac{e^{z_{i2}}}{e^{z_{i1}} + e^{z_{i2}}} = 1 - P(x_i \sim 2 | W)$$
    \noindent  Из чего следует, что вероятность второго класса напрямую выражается из вероятности первого. Тем самым выполняется не только условие нормировки вероятностей, но и совпадение постановки задачи мультиномиальной логистической регрессии с числом классов равным $m=2$ с постановкой таковой для бинарной логистической регрессии.

\section{Составление признакового пространства}
    Важной составляющей решения является определение оператора перевода строковых данных в числовые векторы признакового пространства. В данной работе принято решение воспользоваться методом построения мешка слов (\textbf{BagOfWords}). Такой метод предполагает, что исходный смысл каждого из предложений сокрыт в наборе слов, в нем используемых. Таким образом мы выделяем новое понятие — слово — как смысловую единицу, отказываясь от упорядоченности слов и разбиения текстов на предложения, абзацы и так далее; само же действие оператора перевода на корпус текстов осуществляется примерно следующим образом:

    \begin{enumerate}
        \item Пройдя по всему корпусу текстов, собрать данные о всех словах: число различных слов, число встреч каждого слова, возможно составления набора подцепочек слов и так далее.
        \item За второй проход по корпусу, каждому предложению в соответствие поставить вектор, размерности числа различных слов, встреченных за первый проход, где каждому слову ставится в соответствие некоторое число, полученное как функция от числа встреч этого слова в данном тексте от данных, полученных за первый проход.
    \end{enumerate}

    \noindent И уже в определении самой функции сопоставления слову числа в получаемых векторах эмбедингов является главной задачей в построении нашего оператора перевода $\mathcal{V}$

    \subsection{Предобработка текстов}

    Исходя из полученного определения оператора перевода текстовой информации в удобную для компьютера векторную, получаем необходимость в определении понятия слова и его информативности. Последнее желание понятно, так как отсутствие влияния слова на смысловую окраску предложения сигнализирует, что такое слово, отражаясь на конечном признаковом пространстве, будет лишь мешать работе модели. Потому введем требования на лексемы, что мы будем оставлять в для алгоритма сбора мешка слов:

    \begin{itemize}
        \item Лексемы (слова) разделены пробелом.
        \item Лексемы могут быть произвольной длины и необязательно значить что-либо на исходном языке.
        \item Лексемы должны быть качественными индикаторами того, что данное предложение относится к соответственному классу (присутствие данного слова в предложении дает нам возможность предположить окраску предложения).
    \end{itemize}

    \noindent Исходя из данного описания можно вывести конкретный список действий, применение которых могло бы улучшить качество классификации:

    \begin{enumerate}
        \item Приведение слов к нижнему регистру — так теряется смысл заглавных букв, однако слова по типу "Береза" и "березыа" обретают одинаковый смысл, что в большинстве случаев подпадает под наши нужды.
        \item Замена всех специальных символов на пробелы — действие призвано убрать незначащие для классификации эмоциональной окраски текстов повторяющиеся пробелы и символы типа "<", ">", ":", "+" и так далее.
        \item Замена чисел, записанных символами цифр, эквивалентными словесными записями — такой подход позволит рассматривать сложные числительные как набор из одинаковых слов, при этом делая их эквивалентными числительными, изначально записанным в словесной форме.
        \item Удаление стоп-слов — удаление повсеместно используемых слов союзов, местоимений, слов паразитов и так далее, что не присущи какой-то одной эмоциональной окраске.
        \item Применение Стемминга или Лемматизации — применение средств, позволяющих привести различные формы слов к одной, тем самым сильно сократив размерность мешка слов. (исследуются далее)
    \end{enumerate}

    \subsection{Перевод корпусов текстов в матричное представление}
    \begin{leftrule}
        Требуется получить представление вектора размерности $l$ (размерности переводимой выборки), компонентами которого являются строки, в матрицу размерности $q \times l$, где $q$ является размерностью конечного признакового пространства, а $l$ - количество объектов в выборке соответственно. \\[-0.5in]
    
        \begin{align*}
            u^l = (u_1, u_2, ..., u_l), u_i \in \mathfrak{U}^{\ae} \Longrightarrow & 
            \begin{pmatrix}
                x_{11} & ... & x_{1l}\\
                x_{q1} & ... & x_{ql}
            \end{pmatrix} 
            \in \mathds{R}^{q \times l}
        \end{align*}
    \end{leftrule}

    При определении оператора перевода $\mathcal{V}$ можно рассматривать различные эвристики, связанные с получением итогового числового коэффициента каждого признака в эмбединге. В исследовании использовались два типа операторов перевода:

    \begin{enumerate}
        \item Оператор, не учитывающий относительную частоту появления слова в корпусе $(\mathcal{V}_{cv})$ — Такой оператор дважды проходится по всему корпусу текстов, составляя множество всех слов, используемых в текстах, после чего создает матрицу встречаемости каждого из слов в каждом тексте. Тем самым эмбединг строки представим последовательностью чисел, равных числу встречаемости слова в соответствующей строке.
        \item Оператор, это число учитывающий $(\mathcal{V}_{fidv})$ — действует подобно предыдущему, с той лишь разницей, что он строит не матрицу встречаемости слов, а матрицу веса каждого слова для в текстах, учитывая важность слова на основе частоты его встречаемости как тексте, так и во всем корпусе целиком.
    \end{enumerate}

\section{Анализ градиента  и его численного приближения}

\begin{wrapfigure}{r}{0.4\textwidth}
    \centering
    \includegraphics[width=.98\linewidth]{norm_of_grad_diff_utils_test.eps}
    \caption{График зависимости нормы разницы векторов аналитического градиента   и его приближения от $\varepsilon$}
    \label{fig:norm_of_grad_diff}
\end{wrapfigure}

    Задача классификации, изучаемая в данном исследовании, представляет собой бинарную задачу классификации на положительный и отрицательный класс. Описанный градиент, как формула, был получен аналитическим путем, однако существуют различные численные методы приближения производной функции. 
    
    Рассматривается приближение градиента функции эмпирического риска $L(X, y; w)$ в точке по правилу правой производной покомпонентно. Пусть $\sigma_i^j$ — символ Кронекера, равняющийся единице при $i=j$, и нулю при любых других случаях. Тогда запись $\{\sigma_i^j\}$ будет обозначать вектор, где на $i$ месте стоит 1 и 0 на всех остальных:


    \begin{align*}
    & \nabla L(X, y; w)=\substack{lim \\ \varepsilon \rightarrow 0+0} \frac{L(X, y; w + \varepsilon h) - L(X, y; w)}{||\varepsilon h||} \\
    & \nabla_{i} L(X, y; w)= \substack{lim \\ \varepsilon \rightarrow 0+0} \frac{L(X, y; w + \varepsilon \{\sigma_i^j\}) - L(X, y; w)}{\varepsilon} 
    \end{align*}

    Тем самым каждая компонента вектора градиента функции эмпирического риска может быть получена как конечная разностная дробь, что из условия всюду непрерывной дифференцируемости функционала ошибки $L$ по $w$ при стремлении $\varepsilon$ к нулю должна стремится к аналитической формуле градиента.

    Проверка такого свойства возможна статистическим путем. Будем смотреть на убывающую в геометрической прогрессии последовательность $\varepsilon_i$, для каждой из которых будем генерировать 100 случайных выборок размерности $5000 \times 32$, где 32 - число признаков каждого из 5000 объектов и для каждой из них будем смотреть разницу в случайной точке $w_{ij}$, взятой из нормального распределения. По каждой итерации берем нормы разницы между векторами, получаемыми в одной точке с помощью аналитической формулы и формулы конечно-разностных приращений, и по каждой $\varepsilon_i$ усредняем средним арифметическим. 
    
    На графике \ref{fig:norm_of_grad_diff} изображена тенденция к постоянному падению средней  нормы разницы между описанными векторами вплоть до определенной границы возле $\varepsilon=10^{-7}$, после чего график средней ошибки увеличивается практически с такой же скоростью, что и снижался до этого момента. Такое наблюдение можно связать с неидеальностью представления чисел с плавающей точкой нашими компьютерами, из чего следует неэффективность использования конечно-разностных схем при точной работе, так как довольно быстро метод достигает максимума своей точности, и дальнейшее уменьшение коэффициента $\varepsilon$ только ухудшает конечную оценку аналитической функции. 

    
\section{Исследовани градиентного спуска Логистической регрессии}

    Очистим изначальную выборку от специальных символов и приведем все знаки к нижнему регистру. Применим к получившемуся датасету оператор $\mathcal{V}_{cv}$, отбросив все слова, встречающиеся реже чем в 50 текстах.
    
    Реализация решения оптимизационной задачи, поставленной во втором разделе исследования, проводится на основе градиентного спуска, при котором на каждом шагу (итерации) производится изменение весов $w$ в сторону антиградиента с некоторым коэффициентом. Описать структуру подхода можно следующим образом:

    \begin{enumerate}
        \item На $0$ шаге алгоритма инициализируем каким-либо способом веса и строим последовательность $\{{lr}_i\}_{i=1}^{\infty}$, так называемую последовательность \textbf{learning-rate}, в которой $\forall i \geqslant 0: {lr}_i > 0$.
        \item На $i$ шаге высчитываем градиент функции эмпирического риска ${gr}_i$ при параметрах, на данный момент известных оптимизатору $(X^l, y, w_i)$. Важным замечанием здесь является то, что градиент высчитывается сразу по \textbf{всем} объектам обучающей выборки.
        \item Производится шаг градиентного спуска, при котором высчитываются новые веса алгоритма: $w_{i+1}=- {lr}_i \cdot {gr_i}$
        \item Алгоритм проверяет условия выхода из цикла: например по достижению максимального числа итераций либо при достижении алгоритмом состояния, когда при $i$ шаге функция потерь убывает не более чем на заранее заданное число
    \end{enumerate}

    \begin{leftrule}
        Важным замечанием здесь является условие на определение \textbf{learning-rate}. Из теоремы о сходимости численного метода оптимизации следуют ограничения на данный ряд: $\sum_{i=1}^{\infty}{{lr}_i}$ — расходится, $\sum_{i=1}^{\infty}{{lr}_i^2}$ — сходится
        \noindent при таком задании последовательности можно утверждать, что алгоритм всегда сойдется к оптимуму при бесконечном количестве итераций.
    \end{leftrule}
    
    Таким образом решение оптимизационной задачи и конечная модель зависит от выбора \textbf{learning-rate} и начального приближения. При чем изменение каждого из параметров неизбежно повлечет за собой изменения не только самой сходимости модели, но и ее работы на тестовой и обучающей выборках. Оценка же алгоритмов должна основываться не только на скорости сходимости, но и на метриках качества итоговой модели. Будем рассматривать, исходя из условия задачи по выявлению токсичных комментариев (положительного класса, следующие статистики:

    \begin{itemize}
        \item сходимость loss функции (значение функции эмпирического риска)
        \item поведение accuracy на тестовой выборке
        \item precision и recall положительного класса на тесте
        \item F1-score как гармоническое среднее от precision/recall
    \end{itemize}

    \subsection{Исследование learning-rate}

        В исследовании использовался метод инвертированной прогрессии для реализации \textbf{learning-rate}, формула которой представима в виде $\eta_i=\frac{\alpha}{\beta^i}$, где коэффициенты $\alpha$ и $\beta$ являются гипер-параметрами. Такое определение последовательности достаточно удобно в работе, так как позволяет выбрать не только масштаб шага, но и скорость его убывания, при этом не требуя заранее известного числа итераций, как некоторые остальные методы задания \textbf{learning-rate}. В дальнейшем будем работать с моделями, имеющими $L_2$ регуляризацию с коэффициентом, равным 1.0, и не имеющими критерия остановки по разнице функции эмпирического риска на итерациях.

    \subsubsection{Сходимость модели}

    
        Первая характеристика каждой модели является ее скорость сходимости на предоставленной обучающей выборке. Оценим поведение сходимости на фиксированных данных для параметров $\alpha, \beta$ по сетке, выпустив "пучок" моделей с одинаковыми начальными данными для разных \textbf{learning-rate}.

        Выбор beta состоит из набора $\{0, 0.3, 0.7\}$, так как он хорошо приближает реальную действительность. Если мы не хотим никак уменьшать шаг на итерациях, мы будем использовать 0, если же мы проваливаемся в локальные минимумы или не можем сойтись при большом количестве итераций к глобальному минимуму, однако не хотим испытывать проблемы с осцилляцией модели, будем брать малые значения, например 0.3, если нам надо очень быстро убрать шаг, будем использовать значения в области единицы, в нашем случае 0.7. При этом значения коэффициента масштаба $\alpha$ проходит значения множество значений от ${10}^{-3}$ до ${10}^{0.3}$
        
        Процесс обучения моделей с описанными коэффициентами изображен на графике \ref{fig:loss_gdc_compare}. Цветовая гамма выбрана из соображений скорости сходимости моделей, и идет от синей гаммы — самых медленных и инертных моделей, к более быстрым, зеленым моделям. Можно легко заметить, что при любых $\beta$ быстрее всего сходимость к плато присутствует у моделей с самым большим $\alpha$, при чем с ростом коэффициента резко растет именно первые шаги, проходимые алгоритмом, что косвенно подтверждает предположение о природе и роли $\alpha$. От $\beta$ же явным образом зависит скорость убывания обучения, что наблюдается при сравнении трех графиков одновременно: с ростом $\beta$ кривые становятся более пологими, а количество моделей, сумевших достичь оптимума за конечное число итераций, равное 200, с увеличением $\beta$ монотонно уменьшается. Работу различных параметров можно сравнить с гибкостью обучения модели:
        
        \begin{itemize}
            \item параметр $\alpha$ — отвечает за гибкость модели на всем протяжении обучения.
            \item параметр $\beta$ — отвечает за потерю такого качества, как гибкость, со временем
        \end{itemize}

        Отдельно в процессе обучения моделей присутствует особенность, сводящаяся на нет с ростом $\beta$: алгоритм, при относительно больших $\alpha$ и относительно малом $\beta$ имеет свойство осцилляции в районе оптимума (ярко видно на примере $\beta$=0 и так же присутствует на $\beta$=0.3). Такое поведение говорит о неустойчивости процесса обучения, а потому его стоит избегать, хотя желание увеличить $\alpha$ естественно. Потому при росте $\alpha$ следует увеличивать и параметр $\beta$
        
    \begin{figure}[t]
        \centerline{\includegraphics[width=0.95\paperwidth]{gdc_loss_compare.eps}}
        \caption{Сходимость алгоритмов GDC при различных параметрах \textbf{learning-rate}}
        \label{fig:loss_gdc_compare}
    \end{figure}

        
    \subsubsection{Качество модели}

    \begin{figure}[t]
        \centering
        \includegraphics[width=0.88\textwidth]{gdc_precsion_recall_compare.eps}
        \caption{Precision и Recall моделей}
        \label{fig:precsision_recall_gdc}
    \end{figure}

        Выберем семейство моделей с параметром $\beta=0.3$, как некоторое усреднение полученных ранее результатов. Как предполагает задание, неотъемлемой частью итоговой модели должно являться умение определять положительный класс, делать это с хорошей точностью, не классифицируя обычную речь как токсичную, но и не пропускать действительно токсичные высказывания. Первое выливается в требования на достаточно больший $precision$, в то время как последнее выливается в требование на большой $recall$. Оценим поведение данных метрик на валидации для оговоренных моделей с помощью графиков \ref{fig:precsision_recall_gdc}

        График precision показывает, как модели с относительно большим коэффициентом $\alpha$ имеют склонность к осцилляции около в плато, на которое они вышли. При этом модели с малыми коэффициентами демонстрируют противоположный результат, где они оказались не способными покинуть свое начальное (инициализированное) состояния ввиду своей малой гибкости на обучении. 

        При этом, если график precision радует хорошими показателями, график recall показывает крайне плохие результаты, относительно precision. Мы видим, как большинство моделей, с большими показателями $\alpha$ показывают около нулевые метрики recall, косвенно говоря, что модели предпочитают определению обоих классов константное предсказание, при котором почти всем объектам ставится в соответствие отрицательный класс.

    \begin{figure}[h]
        \centering
        \includegraphics[width=0.88\textwidth]{gdc_accuracy_f1_compare.eps}
        \caption{accuracy и F1-score моделей}
        \label{fig:accuracy_f1_gdc}
    \end{figure}

        Проясняет ситуацию график \ref{fig:accuracy_f1_gdc}, где видно, что модели с минимальным recall быстро выходят на плато и остаются там на протяжении всех итераций обучения. Это ожидаемо, так как вся ошибка, влияющая на accuracy, заключена в тех положительных объектах, что были классифицированы как отрицательные. В тестовом датасете отношение числа объектов с отрицательным классом к положительным действительно равняется 7/3. Подобно precision, модели с малыми показателями $\alpha$, остаются в начальном состоянии и не способны никак обучиться на данных. 

        График F1-score показывает усреднение гармоническим от precision и recall на каждой итерации. Видно, что самыми лучшими результатами обладают как раз необученные ввиду отсутствия гибкости (с малыми $\alpha$) модели, оставшиеся по своей классификационной способности на уровне начального приближения. При этом, гибкие модели имеют крайне малый скор, что было ожидаемо из графика recall.

    \subsubsection{Почему такое могло произойти}

        Поведение модели явным образом указывает на то, что она посчитала предсказание отрицательного класса на всех объектах более выгодным, нежели другие стратегии. Такое поведение может быть вызвано переобучением модели, либо несбалансированностью примеров классов в обучающей выборке. Для дальнейшей работы останемся с тем же датасетом.

    \subsection{Исследование начального приближения}

        Большую роль в сходимости и даже конечном результате может играть именно начальное приближение весов при инициализации модели. Именно от этого аспекта сильно зависит вопрос о попадании модели в локальные минимумы, время достижения глобального оптимума, то, какие показатели по метрикам будет показывать модель во время обучения.
        
        Используются различные эвристики, что можно условно разделить на стохастические и детерминированные приближения. В исследовании рассматривались несколько способов определения начального приближения весов:

        \begin{enumerate}
            \item Приближение коэффициентами из нормального распределения
            \item Приближение коэффициентами из равномерного распределения
            \item Приближение коэффициентами из распределения Лапласа
            \item Приближение коэффициентами из распределения Гампбела
            \item Приближение нулевым вектором
            \item Приближение значимостью признаков ($w_i = \frac{(f_i, y)}{(f_i, f_i)}$, где $f_i$ — соответсвующий столбец признака у объектов)
        \end{enumerate}

        \begin{leftrule}
            Если первые три распределения практически очевидны для понимания, то распределение Гампбела позволяет описать случай, большинство признаков объектов играет достаточно малую роль в определении положительного класса, при этом малое количество признаков играют сильную роль в определении отрицательного класса. Такая характеристика могла бы помочь в данной задаче. 
        \end{leftrule}
        
        Так как в опытах присутствует важный аспект случайности, необходимым является сбор статистической информации. За основу была взята модель с показателями \textbf{learning-rate} как 0.5, 0.5, с коэффициентом регуляризации $L_2$ равным 1.0. Для каждого из методов проведено 5 опытов и на их основе построены графики \ref{fig:gdc_init_weigths_loss}

    \begin{figure}[h]
        \centering
        \includegraphics[width=0.88\textwidth]{gdc_init_weights_loss.pdf}
        \caption{средний loss со среднеквадратическим отклонением при разных приближения}
        \label{fig:gdc_init_weigths_loss}
    \end{figure}

        Видно, что большинство инициализирующих начальных приближений ведут себя примерно одинаково, имея большую ошибку при первых итерациях и быстро сходясь к минимуму при обучении. При этом среднеквадратическое отклонение значения функции эмпирического риска с ростом числа пройденных итераций обучения только увеличивается, что подтверждает начальное предположение о возможном попадании в локальные минимумы. Лучшим начальным приближением в этом плане оказалось приближением нулевым вектором, имея наименьшую дисперсию и наилучший loss начиная с первой же итерации. 

        Такое поведение приближения нулевым вектором объяснимо прошлыми наблюдениями, что предсказывание класса моделью, практически константно для всех объектов. Однако при этом по метрике F1-score \ref{fig:gdc_accuracy_f1_for_init_weights} лидирует именно приближение Гампбела, что согласуется с выдвинутой теорией о применимости такого распределения. Большинство моделей стремятся к общему плато и ведут себя примерно одинаково. В отличие от приближения значимостью признака, активизирующего accuracy минимизацией F1-score. 
            

    \begin{figure}[t]
        \centering
        \includegraphics[width=0.88\textwidth]{gdc_accuracy_f1_for_init_weights.eps}
        \caption{усредненные accuracy и F1-score для различных начальных приближений}
        \label{fig:gdc_accuracy_f1_for_init_weights}
    \end{figure}

\section{Исследование стохастического градиентного спуска Логистической регрессии}

    Результаты градиентного спуска на первично обработанных данных не показал больших успехов. Однако оценим работу модели логистической регрессии, решающей оптимизационную задачу благодаря алгоритму стохастического градиентного спуска. Его главное отличие от алгоритма градиентного спуска заключается в том, что на каждой итерации модель высчитывает градиент шага только по подвыборке всех элементов. Такой подход способен быть более быстрым при подсчете и даже при обучении, а так же способен быть реализован таким образом, что в каждый момент времени компьютеру не обязан держать всю выборку в памяти. Однако при этом он более склонен к переобучению и сильно зависит от случайности.

    Будем говорить, что алгоритм прошел "эпоху", когда он перебрал все возможные непересекающиеся подвыборки (почти одинаковой мощности) из датасета за цикл. Таким образом обучение представляет собой прохождение по частям датасета, а число итераций алгоритма равно числу эпох, пройденных им за время обучения.

    Из определения стохастического градиентного спуска вытекает существование еще одного важного аспекта, от которого может зависеть обучение и поведение модели, помимо \textbf{learning-rate} и начального приближения - размер подвыборки, по которой алгоритм высчитывает градиент на итерациях. Изучим поведение стохастического градиента для задачи Логистической регрессии по этим трем аспектам.

    \subsection{Изучение \textbf{learning-rate}}

        Рассмотрим функцию эмпирического риска для рассматриваемой задачи с $L_2$ регуляризацией:

        $$L(X^l, y; w) = \frac{1}{l}\sum_{i=1}^{l}{\ln(1+exp\{-y_i \left\langle w, x_i \right\rangle - w_0\})} + \frac{\gamma}{2}{||w||}^2$$

        Данный функционал представляет собой сумму выпуклых функций (следует из определения логарифма) и строго выпуклой функции (добавочного члена регуляризации), из чего следует строгая выпуклость функции риска. Из курса методов оптимизации, для такого функционала действует теоремы "О выпуклой оптимизации" и "О стохастической аппроксимации", говорящие, что при правильно выборе скорости сходимости (\textbf{learning-rate}) градиентный спуск сходится почти наверное к глобальному минимуму. Таким образом начальное предположение состоит в том, что стохастический градиентный спуск будет вести себя примерно так же на данных, что и градиентный спуск. Будем собирать статистику по модели за время обучения дважды за одну эпоху. Число эпох поставим равным 200.

        \subsubsection{Обучение}
    
        \begin{figure}[t]
            \centerline{\includegraphics[width=0.95\paperwidth]{sgdc_loss_for_alphas.eps}}
            \caption{Сходимость алгоритмов SGDC при различных параметрах \textbf{learning-rate}}
            \label{fig:sgdc_loss_for_alphas}
        \end{figure}
    
            Таким же образом, что и для градиентного спуска, выпустим "пучок" моделей по оговоренной сетке с начальным приближением вектором из нормального распределения. Графики динамики обучения представлены ниже \ref{fig:sgdc_loss_for_alphas}. Как можно заметить, главное различие между графиками для \textbf{GDC} (градиентного спуска) и \textbf{SGDC} (стохастического градиентного спуска) является большая ломаность кривых обучения, вызванное тем, что алгоритм раз за разом переобучается на малых наборах объектов. Однако общая зависимость обучения от параметров $\alpha$ и $\beta$ повторяет таковую для градиентного спуска.  

        \subsubsection{Качество алгоритмов}
        
            Сравним статистики accuracy и F1-score относительно положительного класса, как основополагающие оценки при анализе данной задачи.
            Сразу заметен тот факт, что некоторым алгоритмам удалось улучшить свое качество, относительно алгоритма градиентного спуска. За 200 итераций некоторые алгоритмы достигли качества в 0.75, при максимуме в 0.71 для GDC. При этом здесь же в большей степени проявляется большая ломанность кривых, что была отмечена еще на графиках функции эмпирического риска, вызванная обучаемостью алгоритма каждый раз на отдельных пачках объектов. 

            Так же заметно большее число алгоритмов, сумевших достичь относительно большего показателя F1-score при большом показателе accuracy. Данное наблюдение возможно из того, факта, что для стохастического градиентного спуска несбалансированность классов играет меньшую роль, нежели чем для градиентного спуска.


    \subsection{Изучение начальных приближений}

\begin{wrapfigure}[28]{l}{0.5\textwidth}
    \centering
    \includegraphics[width=0.3\paperwidth]{sgdc_accuracy_f1_compare.eps}
    \caption{График изменения метрик accuracy и F1 на тесте в процессе обучения}
    \label{fig:sgdc_accuracy_f1_compare}
\end{wrapfigure}
        Посмотрим на процесс обучения моделей с коэффициентом регуляризации равным 1 и значения $\alpha$ и $\beta$ по 0.5 на графике \ref{fig:sgdc_init_weight_loss_compare}. Видно, что стохастический градиентный спуск даже смог улучшить картину обучения, для большинства приближений уменьшив дисперсию значений. Однако в общих чертах поведение по сходимости моделей остается неизменным для обоих оптимизационных алгоритмов. 

        Что является более важной характеристикой, так это конечное качество алгоритмов, представленное на графике \ref{fig:sgdc_accuracy_f1_for_init_weights}. Мы можем видеть общее улучшение качества по метрике F1-score для практически всех начальных приближений. Однако наилучшим образом проявило себя приближение значимостью признака, в отличие от градиентного спуска.
        Фиолетовая кривая показывает большие показатели как precision, так и recall, имея при этом большой коэффициент accuracy, а факт того, что данный график является усреднением от нескольких опытов, показывает эффективность именно такого подхода к построению модели на данных. Так же стоит отметить второй по характеристикам метод приближения распределением Гампбелла.
   
    \begin{figure}[t]
        \centering
        \includegraphics[width=0.88\textwidth]{sgdc_init_weight_loss_compare.pdf}
        \caption{усредненный loss при обучении для различных начальных приближений SGDC}
        \label{fig:sgdc_init_weight_loss_compare}
    \end{figure}


    \begin{figure}[h]
        \centering
        \includegraphics[width=0.88\textwidth]{sgdc_accuracy_f1_for_init_weights.eps}
        \caption{accuracy и F1-score моделей для разных начальных приближений}
        \label{fig:sgdc_accuracy_f1_for_init_weights}
    \end{figure}


    \subsection{Оценка зависимости обучения SGDC от размера подвыборок}

        Алгоритм стохастического градиента, как было замечено, в каждый момент времени работает лишь с частью всей обучающей выборки. Вводится понятие \textbf{batch-size}, размер таких групп, либо как абсолютное число объектов, попадающий в каждую группу, либо как доля объектов из доступной выборки, что на каждой итерации попадает в свою группу. В общем случае, на каждой эпохе объекты перемешиваются, чтобы убрать эффект переобучения. 


        Зафиксируем модель с коэффициентом регуляризации $L_2$ равным 1.0 и коэффициентами $\alpha$ и $\beta$ равными 0.5. Модель обучалась на фиксированной обучающей выборке с различными коэффициентами \textbf{batch-size} в диапозоне от 0.05 до 0.65. Далее модель считается обученной, если при итерации loss изменяется менее чем на ${10}^{-5}$. 

\begin{wrapfigure}{r}{0.3\textwidth}
    \centering
    \includegraphics[width=0.3\paperwidth]{sgdc_time_from_batch_size.eps}
    \caption{Общая зависимость времени обучения от \textbf{batch-size}}
    \label{fig:sgdc_time_from_batch_size}
\end{wrapfigure}

        На графике \ref{fig:sgdc_time_from_batch_size} полученная зависимость времени обучения от коэффициента, характеризующего \textbf{batch-size}. При уменьшении такого показателя время обучения в среднем падает, непосредственно показывая, что модели намного легче подстраиваться под каждый объект по отдельности, нежели делать это для подвыборок больших размеров.

\section{Сравнение GDC с SGDC}

    Стохастический градиентный спуск имеет ряд преимуществ по сравнению с детерминимрованной версией, что в зависимости от некой удачи могут сильно улучшить характер работы конечной модели. Все нужные выводы были сделаны ранее, а потому краткая компиляция:
    
    \begin{itemize}
        \item Градиентный спуск позволяет оценивать задачу \\оптимизации для всех объектов в целом. Если для числа задач такой подход может быть намного более удобным, даже необходимым, то в случае данной задачи, такое поведение оптимизатора способно только ухудшить положение при неправильно подготовленных данных.
        \item Стохастический градиентный спуск напротив, способен решить проблему несбалансированности выборки, убрать \\переобученность алгоритма при осознанном ограничении \\числа эпох обучения.
        \item Стохастический алгоритм обучает модель менее "устойчивым" путем
        \item Подход стохастического градиентного спуска позволяет организовать процесс обучения более гибким к памяти компьютера образом, не вынуждая хранить всю выборку в ОП постоянно.
        \item Поведение алгоритмов относительно изменения \textbf{learning-rate} мало отличимо и разница нивелируется при увеличении количества итераций.
        \item Стохастический градиентный спуск позволяет проводить обучение модели намного быстрее детерминированного.
    \end{itemize}

    Можно говорить, что в рамках данной задачи стохастический градиент показал себя более успешно по времени обучения и по конечным метрикам качества. Потому дальнейшую работу предполагается производить на основе \textbf{SGDC}. Однако даже так нельзя утверждать ничего в целом о действительной работоспособности этих моделей относительно друг друга, так как немалую роль в успехах и неуспехах играла именно обучающая выборка, или иначе, ее предобработка. Именно анализ и возможных улучшений в обработке текстовой информации способен привнести большее качество в модели классификации.

\section{Углубленное построение пространства признаков}

    Как отмечалось ранее, специфика поставленной задачи заключается в отсутствии первоначального пространства признаков у объектов. Его поиск является первым и самым важным этапом на пути решения проблемы в целом (классическая задача \textbf{Feature-Selection}). Однако в отличие от, например, прямого построения моделей на подготовленных данных, здесь нельзя напрямую отталкиваться от формализованных метрик качества, а сама задача выливается в набор различных эвристик, которые перебираются в поиске наилучшей.

    Выбранной и фиксированной моделью представления данных является Мешок слов. Однако он, как отмечалось ранее, достаточно сильно зависит как от предобработки текстов, так и от установленного отображения элементов строк в пространство признаков. Задача явным образом делима на две составляющих, а потому рассмотрим каждый из аспектов.

    \subsection{Предобработка текстов}

        Вне зависимости от методов определения оператора отображения в пространство численных признаков ($\mathcal{V}_{cv}, \mathcal{V}_{fidv}$), вопрос самих отображаемых данных стоит на первом месте. Без качественной обработки символьных цепочек (текстов) на первичном уровне, возникают проблемы с информативностью отдельных лексем, что затрагивались ранее в отчете. Потому рассматривались два основных подхода очистки и приведения текстов с последующим их сравнением с уже используемыми, практически нетронутыми данными: метод \textbf{лемматизации} и \textbf{стемминга}. Воздействуем на все три выборки стандартным $\mathcal{V}_{cv}$, отбрасывающим все слова, встречающиеся реже, чем на 10 текстах. 

        Полученные признаковые пространства имеют размерности 11222, 7874 и 9816 для строк обработанных первоначальными преобразованиями, для данных после стемминга и после лемматизации соответственно. Видно, что наибольшая размерность присуще именно практически нетронутым данным, что вполне ожидаемо. Методы лемматизации и стемминга достаточно сильно уменьшают данное значение, при чем стемминг делает это более агрессивно (практически в два раза относительно лемматизации). Последний факт может как сильно улучшить поведение модели, ее качество и скорость работы, так и значительно ухудшить. Сравним выборки на основе скорости обучения моделей в среднем и итогового качества.


\begin{wrapfigure}[15]{r}{0.3\textwidth}
    \centering
    \includegraphics[width=0.3\paperwidth]{time_consume_comp_for_stem_lem_def.eps}
    \caption{Общая зависимость времени обучения от \textbf{batch-size}}
    \label{fig:time_consume_comp_for_stem_lem_def}
\end{wrapfigure}


        \subsubsection{Скорость сходимости}

            Будем обучать модель с \textbf{learning-rate} равным инвертированной прогрессии с параметрами из сетки: $\beta \in [0.01; 1.0], \alpha \in [0.1, 12]$, приняв коэффициент регуляризации $L_2$ равным 0 и размер батчей для \textbf{SGDC} равным 0.25 от всей выборки.

            Усреднив время обучения по $\beta$, отобразим время затраченное алгоритмами для каждого $\alpha$, высчитывая его как дельта разница между временем начала обучения и временем окончания последней итерации. Итоговые показатели отображены на графике \ref{fig:time_consume_comp_for_stem_lem_def}. Относительно $\alpha$ заметна общая тенденция на уменьшение времени обучения с ростом коэффициента, что является ожидаемым эффектом и наиболее выражено у данных после применения стемминга. Однако имея одинаково плохую сходимость в точке минимального $\alpha$, модели, обученные на данных с различной примененной обработкой, ведут себя по-разному при изменении коэффициента. Если стемминг с ростом $\alpha$ показывает стабильное \\повышение скорости обучения, то лемматизированные \\данные сильно зависят от коэффициента.
            
            Для лемматизированных данных время, затраченное на обучения, стремительно падает до определенного момента и вновь повышается на уровень с изначальными данными. Такое поведение объясняется тем, что лемматизированные данные, в отличие от стеммированных, сохраняют больше "контекста" слова, а потому больший \textbf{learning-rate} не позволяет им сойтись, заставляя модель осциллировать около оптимума.

        \subsubsection{Качество получаемых моделей}

            Оценка качества обучения производится на основе конечных показателей метрик качеств моделей: на основе accuracy и F1-score. Данные о тестах агрегированы в таблицы \cref{table:default_lemmatized_and_stemmed_dataset_comparision:default,table:default_lemmatized_and_stemmed_dataset_comparision:lemm,table:default_lemmatized_and_stemmed_dataset_comparision:stem}, где значения метрик на валидационой выборке приведены для всех комбинаций коэффициентов \textbf{learning-rate}. 

            Видно, что на каждой из выборок модели смогли достигнуть примерно одинакового наилучшего результата: accuracy 0.89, F1-score 0.827, при чем такие результаты были достигнуты при самых мылых коэффициентах $\beta$, что можно связать с большой размерностью эмбеддингового пространства. При этом для каждого метода существует своя $\alpha$, доставляющая лучшее качество на валидации, возле которой кучкуются другие наилучшие результаты модели по данной выборке. Тем самым косвенно показывается, что соответственный выбор коэффициентов находится в области устойчивого оптимума выбора \textbf{learning-rate}.

            В общем случае заметна большая разница между результатами, полученными ранее (при анализе градиентного спуска) и здесь. Видно, что предобарботка документов способна крайне сильно улучшить классификационную способность алгоритма. Вне зависимости от того, что модель Логистической регрессии смогла показать свою способность доставлять хорошее качество на каждой из доступных выборок, заметно общее превалирование по метрикам качества моделей, обученных на выборках с лемматизацией и стеммингом относительно моделей, обучавшихся на стандартных данных.
            
            
    \subsection{Исследование оператора перевода $\mathcal{V}$}

        Качественная предобработка текстовой информации при прочих равных, способна улучшить качество модели, уменьшить время обучения, а так же изменить размерность итогового признакового пространства. Однако главная роль в создании итоговых эмбеддингов отводится именно оператору перевода. В зависимости от выбора стратегии (учета или неучета частоты встречи слов) и входных параметров ${min}_{df}$ и ${max}_{df}$ (минимального и максимального числа встреч слова соответственно, чтобы попасть в итоговое пространство), устройство эмбеддингов может кардинально отличаться для двух разных операторов, что несомненно отразится и на работе модели. Проведем оценку такого влияния каждого из двух операторов на выборку с лемматизацией, и сравним их между собой.

        Будем прогонять по сетке значения ${min}_{df}$ и ${max}_{df}$ для двух операторов, взяв за основу мер качества три критерия:
        \begin{itemize}
            \item Размерность итогового признакового пространства — меньшее признаковое пространство позволяет избежать многих проблем с переобучением модели, свести требуемый размер обучающей выборки к минимуму, придать модели больше устойчивости во время обучения
            \item Время обучения модели
            \item Качество получаемых моделей
        \end{itemize}

        Пройдемся по порядку по каждому из пунктов.

\begin{wraptable}[11]{l}{10cm}
    \caption{Размерность признаков }
    \label{tab:domain_sizes}
    \begin{tabular}{|r|r|r|r|r|r|r|r|r|}
    \hline
    
min\textbackslash{}max &    40 &    75 &   150 &   250 &   600 &   1 \\
\hline
             0 & 75474 & 76832 & 77875 & 78415 & 78948 & 79465 \\
\hline
            10 &  5825 &  7183 &  8226 &  8766 &  9299 &  9816 \\
\hline
            20 &  2342 &  3700 &  4743 &  5283 &  5816 &  6333 \\
\hline
            50 &  -1   &    881 &   1924 &  2464 &  2997 &  3514 \\
\hline
           100 &  -1   &    -1 &    575 &   1115 &  1648 &  2165 \\
\hline
           200 &  -1   &    -1 &    -1 &    227 &   760 &   1277 \\
\hline
           300 &   -1  &    -1 &    -1 &    -1 &    392 &   909 \\
\hline
           500 &   -1 &     -1 &    -1 &    -1 &    96 &    613 \\
\hline 
    \end{tabular}
\end{wraptable}


        \subsubsection{Размерность пространства признаков}

            Так как операторы $\mathcal{V}_{cv}$ и $\mathcal{V}_{fidv}$ определяют размерность пространства единым образом, различаясь лишь в вопросе определения компонент вектора эмбеддинга для объектов, будем рассматривать зависимость размерности для двух операторов одновременно, в зависимости от ${min}_{df}$, ${max}_{df}$ и изначальной выборки. 
\clearpage
            Видно, как при малейшем увеличении нижней границы (с нуля до 10) по допуску слов, стремительно падает размерность признакового пространства. Это следует из присутствия в данных множественных примеров лексем, почти более не встречаемых в корпусе текста. Классификация по таким словам будет работать крайне плохо, так как они с малой вероятностью являются типичными представителями своего класса, а потому могут быть нами проинтерпретированы в качестве выбросов. При дальнейшем увеличении нижней границы убавление размерности наблюдается, но скорость сильно уменьшается. Такое поведение может отражать ситуацию, когда часть отсекаемых слов все же несла смысловую нагрузку. При этом видно, что существуют и противоположные слова (порядка 500 штук) что встречаются в большом числе текстов (больше 600). Такие слова могут быть так же не эффективны при обучении модели, так как являются скорее типичными для данного корпуса текстов, нежели типичными отдельному классу. 

        \subsubsection{Оценка времени обучения}

            Время обучения, как мера качества алгоритма, может не быть лишь показателем быстродействия модели и ее удобством использования. Время, затраченное на обучение, показывает скорость сходимости модели, а потому посредством сравнения полученных результатов может многое сказать об эффективности обучения модели на данных. Все так же обучим набор моделей \textbf{SGDC}, с коэффициентом регуляризации $L_2=0.01$, и равными для всех коэффициентами \textbf{learning-rate}: $\alpha=7, \beta=0.01$.

\begin{table}[h]
    \caption{Сравнение времен обучения моделей после применения операторов перевода в секундах}
    \label{tab:table_with_times_for_operators}

    \centerline{
    \begin{tabular}{|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|}
    \hline
       \multirow{2}{*}{min\textbackslash{}max} & \multicolumn{6}{c|}{Время при обработке CountVectorize} 
       & \multicolumn{6}{c|}{Время при обработке TfidfVectorizer} \\
       \cline{2-13}
       & 40 & 75 & 150 & 250 & 600 & 1 & 40 & 75 & 150 & 250 & 600 & 1\\
    \hline
       0.0 & 0.969 & 0.931 & 2.573 & 6.841 & 2.615 & 9.949  & 2.045  & 2.286 & 2.624  & 2.752 & 3.986 & 11.842\\
    \hline
        10 & 0.323 & 0.43 & 0.633 & 1.842 & 0.651 & 14.473 & 1.221 & 3.035 & 1.816 & 2.988 & 2.867 & 8.108\\
    \hline
        20 & 0.576 & 0.398 & 0.265 & 2.637 & 2.407 & 10.944 & 1.034 & 2.555 & 1.669 & 2.03 & 2.712 & 9.214\\
    \hline
        50 & -1 & 0.042 & 0.362 & 0.727 & 0.223 & 11.685 & -1 & 0.985 & 1.362 & 1.716 & 2.448 & 10.382\\
    \hline
        100 & -1 & -1 & 0.266 & 0.6 & 0.316 & 11.744 & -1 & -1 & 2.156 & 1.514 & 2.222 & 13.21\\
    \hline
        200 & -1 & -1 & -1 & 0.398 & 0.086 & 7.862 & -1 & -1 & -1 & 1.815 & 1.711 & 7.208\\
    \hline
        300 & -1 & -1 & -1 & -1 & 0.047 & 7.036 & -1 & -1 & -1 & -1 & 1.377 & 6.592\\
    \hline
        500 & -1 & -1 & -1 & -1 & 0.022 & 6.408 & -1 & -1 & -1 & -1 & 0.984 & 6.136\\
    \hline
    \end{tabular}}
\end{table}

        Из таблицы \ref{tab:table_with_times_for_operators} видно, что на большинстве значений пар ${min}_{df}$ и ${max}_{df}$ метод \textbf{CountVectorizer} сходится быстрее при прочих равных, в редких случаях отставая от \textbf{TfidfVectorize}, что можно считать погрешностью работы компьютера. Сопоставляя с данной таблицей таблицу с размерностями пространств \ref{tab:domain_sizes}, можно увидеть, что при уменьшении размерности пространства модели, обучаемые на данных, обработанных \textbf{CountVectorizer}, сходятся на порядок быстрее за исключение случая при ${max}_{df}=1.0$. 

    \subsubsection{Сравнение качества моделей}
    
        Сравним классификационную способность моделей, обученных на каждой из выборок, полученных после применения соответствующих операторов перевода. Вопреки желанию зафиксировать отдельные модели и прогнать каждую на полученных датасетах для каждого $\mathcal{V}$, в общем случае так делать неверно. При прочих равных, оператор перевода $\mathcal{V}$ достаточно сильно воздействует на сходимость. Зафиксируем из соображений охвата наибольшего числа возможных вариантов выбора ${min}_{df}$ и ${max}_{df}$ несколько пар, для каждой из которых определим оператор перевода и посмотрим на динамику обучения моделей на соответствующих получившихся выборках.

        \begin{leftrule}
            Выбрали несколько выделяющихся вариантов для пар параметров:
            \begin{itemize}
                \item ${min}_{df}=10$, ${max}_{df}=1.0$ - выбор такого оператора может быть обусловлен желанием сохранить как можно больше возможных полезных лексем, в предположении, что от возможно затесавшихся вместе с ними шумовых слов будет меньше вреда, чем от интересующих нас слов пользы.
                \item ${min}_{df}=50$, ${max}_{df}=1.0$ - более агрессивный вариант, при котором мы хотим отсечь большинство (если не все) шумовые слова. Стоит быть осторожным, так как из таблицы \ref{tab:domain_sizes} следует, что при нижнем пороге отсечения в 50 встреч в текстах вполне могут отбрасываться значащие (полезные для классификации) слова.
                \item ${min}_{df}=20$, ${max}_{df}=250$, ${min}_{df}=10$, ${max}_{df}=600$, ${min}_{df}=50$, ${max}_{df}=600$ - специальные "внутренние" варианты выбора рамок для слов. Выбор таких пределов отбрасывания может быть вызван желанием оставить лишь самые эффективные, часто встречаемые, но при этом не шумовые слова, заодно существенно понизив размерность пространства.
                \item  ${min}_{df}=0.0$, ${max}_{df}1.0$ - специальный случай, при котором мы оставляем все слова в выборке.
            \end{itemize}
        \end{leftrule}

        \begin{figure}
            \centering
            \includegraphics[width=1\textwidth]{accuracy_comp_for_diff_operators.eps}
            \caption{Сравнение динамики изменения accuracy на валидации при применении $\mathcal{V}_{cv}$ и $\mathcal{V}_{fidv}$}
            \label{fig:accuracy_comp_for_diff_operators}
        \end{figure}

        Перебрав по сетке параметры для $\alpha$ и $\beta$, приняв размер батча для стохастического градиентного спуска за долю в 0.1 от всей выборки, нашли наилучшие коэффициенты, что привели к наибольшим показателям для моделей: $12, 0.2$ для CountVectorize и $13, 0.01$ для TfidVectorize соответственно. Получившиеся результаты отображены на графиках \ref{fig:accuracy_comp_for_diff_operators}, из которых вытекает несколько важных наблюдений:

        \begin{enumerate}
            \item Модели, построенные на данных от $\mathcal{V}_{cv}$ и $\mathcal{V}_{fidv}$ по своей асимптотике ведут себя крайне схоже, выходя на одни и те же плато на примерно одной и той же итерации
            \item Модели, построенные на основе данных, преобразованных $\mathcal{V}_{fidv}$, на обучении ведут себя намного стабильнее. Такое поведение говорит о большей предсказуемости модели и при прочих равных является крайне желанной особенностью.
            \item Несмотря на начальные предположения об отсечении слишком часто встречаемых слов в текстах, именно модели, не имеющие верхней границы для слов показали лучшее качество
            \item В рамках \textbf{данной конкретной} задачи отсечение большинства слов-шумов (около 60000 лексем) влияет не сколько на качество алгоритма, сколько на скорость сходимости, так как такие модели имеют метрики качества наравне с лучшими.
        \end{enumerate}

    \subsection{Итоги предобработки данных}

        Главной задачей всей предобработки является создание таких данных, на которых модель смогла бы обучаться наиболее предсказуемо и эффективно. Фактически, в классических задачах это достигается внутренними средствами моделей, однако специфика данной задачи в том, что сами данные нужно получать самостоятельно. Очевидным кажется тот факт, что применение средств первичной обработки документов вместе с правильным подбором оператора перевода вместе способны кардинально улучшить работу конечной модели. 

        \begin{leftrule}
            В дальнейшем будем использовать обработку лемматизацией с последующим применение TfidVectorizer с параметрами ${min}_{df}=50$, ${max}_{df}=1.0$.
        \end{leftrule}


\section{Реализация наилучшей модели}

    Соберем наилучшую модель на основе данных, полученных ранее, и проанализируем результаты. Для этого обработаем начальные данные с помощью алгоритма лемматизации с отсеканием слов частотой встреч до 50 в корпусе текстов (${min}_{df}=50$, ${max}_{df}=1.0$) и применением алгоритма TfidfVectorizer; на их основе построим модели \textbf{SGDC} с параметрами размера батчей в 0.1 от всей обучающей выборки и прогоним параметры \textbf{learning-rate} по сетке, выбрав итоговую модель, с наилучшим accuracy \ref{tab:accuracy_final}

\begin{table}[h]
    \centering
    \centerline{
        \begin{tabular}{|c|r|r|r|r|r|r|r|r|r|r|r|}
        \hline
           upper\textbackslash{}lower &     8 &     9 &    10 &    11 &    12 &    13 &    14 &    15 &    16 &    17 &    18 \\
        \hline
                  0.01 & 0.888 & 0.888 & 0.88  & 0.89  & 0.89  & 0.891 & 0.891 & 0.89  & 0.889 & 0.89  & 0.891 \\
                  0.05 & 0.885 & 0.887 & 0.882 & 0.888 & 0.888 & 0.889 & 0.889 & 0.89  & 0.875 & 0.891 & 0.891 \\
                  0.2  & 0.864 & 0.868 & 0.87  & 0.872 & 0.873 & 0.875 & 0.876 & 0.878 & 0.879 & 0.88  & 0.881 \\
                  0.6  & 0.759 & 0.765 & 0.772 & 0.777 & 0.782 & 0.786 & 0.789 & 0.793 & 0.796 & 0.798 & 0.801 \\
        \hline
        \end{tabular}
    }
    \caption{Итоговое качество на моделях при поиске самой наилучшей}
    \label{tab:accuracy_final}
\end{table}

    Большинство моделей имеют примерно хорошие результаты точности (accuracy на валидации) по прошествии обучения, косвенно подтверждая, что проблема с нахождением подходящего обработчика текстовой информации решена успешно. Выберем модель с показателями $\alpha = 18$, $\beta=0.05$, как оптимум, окруженный при этом прочими моделями, достигшими точно такого же результата. 

\begin{wrapfigure}[15]{r}{0.42\textwidth}
    \centering
    \includegraphics[width=0.6\textwidth]{roc_pr_curves.eps}
    \caption{ROC и Precision/Recall кривые лучшего классификатора}
    \label{fig:roc_pr_curves}
\end{wrapfigure}

    Посмотрим на характеристики классификационной способности алгоритма более внимательной. На графиках \ref{fig:roc_pr_curves} изображены графики Precision/Recall относительно положительного класса. При чем мы можем видеть достаточно хорошие результаты, так например \textbf{ROC-AUC} составляет 0.9545, а \textbf{PR-AUC} 0.9056, что говорит большой полноте и точности классификации положительного класса не только на данной моделей, но и на семействе моделей при изменении \textbf{treshhold} определения положительного класса.

    Итоговый объект всей работы получен. Однако даже продвинувшись так далеко классификатор все еще имеет объекты, на которых допускает ошибки. Проведем анализ таких ошибочных объектов.

\begin{wrapfigure}[15]{r}{0.42\textwidth}
    \centering
    \includegraphics[width=0.6\textwidth]{conf_matr.eps}
    \caption{Нормализированные матрицы ошибок на валидации}
    \label{fig:conf_matr}
\end{wrapfigure}

    \subsection{Анализ ошибок классификатора}

        Построим матрицы ошибок, чтобы оценить, куда перевешивает модель в предсказаниях \ref{fig:conf_matr}. Отобразим для удобства матрицу ошибок полученного \\классификатора, нормализованную относительно числа положительных предсказаний модели и числа положительных классов в валидационной выборке. Виден явный, хоть и не большой, перевес в сторону классификации отрицательного класса (здесь 0) как положительного (ошибка первого рода). Из семантики задачи пропуск именно такой ошибки приводит к наибольшему ущербу. Посмотрим на то, как выглядят ошибки классификатором.

\clearpage

        Примеры:
        \begin{itemize}
            \item "== Gay? == \n He's gay too. It should be noted that he has a male partner."
            \item "Hello everyone I'm just here to tell you that you're all freaks"
            \item "I WILL BURN YOU TO HELL IF YOU REVOKE MY TALK PAGE ACCESS!!!!!!!!!!!!!"
            \item "666 the devil will get you all !!!!!!!!!!!!!!!!"
            \item "You wikipedia nazis need to stop removing information"
        \end{itemize}
        
\begin{figure}[b]
    \centerline{\includegraphics[width=0.4\linewidth]{word_cloud.png}}
    \caption{Облако главных 100 слов, имеющих вес в классификации. \textit{Внимание, идея принадлежит не мне. Позаимствовал ее у своего одногруппника. Но она очень красивая, потому просто был обязан вставить.}}
    \label{fig:sgdc_loss_for_alphas}
\end{figure}

        \noindent Как можно видеть, вместе с рядовыми ошибками классификации по пограничным, не всегда даже явно классифицируемых человеком высказываний есть явные ошибки разметки. Это одна из распространенных проблем в машинном обучении, особенно \textbf{NLP}. Бороться с данным типом ошибок практически не возможно в рассматриваемой модели, потому модель можно рассматривать как достаточно качественную.

        \subsection{Какие слова оказались самыми важными для классификации}

        Определить данный факт достаточно просто, благодаря рассматриваемой модели линейной регрессии, где абсолютную величину соответственного коэффициента можно трактовать как значимость соответственного признака. Таковыми являются слова: \textit{fuck, fucking, shit, idiot} и так далее.

\clearpage
\begin{sidewaystable}[b]
\caption{Качество алгоритмов, обученных на данных с \textbf{первичной} обработкой}
\label{table:default_lemmatized_and_stemmed_dataset_comparision:default}
\centerline{
    \begin{tabular}{|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|}
    \hline

    \multirow{2}{*}{beta\textbackslash{}alpha} & \multicolumn{2}{c|}{0.1} &
    \multicolumn{2}{c|}{0.5} & \multicolumn{2}{c|}{1.0} & \multicolumn{2}{c|}{3.0} & 
    \multicolumn{2}{c|}{5} & \multicolumn{2}{c|}{7.5} & \multicolumn{2}{c|}{10} & 
    \multicolumn{2}{c|}{12} \\
    \cline{2-17}
        & Acc & F1 & Acc & F1 & Acc & F1 & Acc & F1 & Acc & F1 & Acc & F1 & Acc & F1 & Acc & F1\\
        
\hline
0.01 & 0.756 & 0.583 & 0.813 & 0.69  & 0.796 & 0.663 & 0.865 & 0.784 & 0.884 & 0.807 & 0.889 & 0.818 & 0.876 & 0.813 & 0.821 & 0.76  \\
\hline
0.05 & 0.746 & 0.568 & 0.804 & 0.674 & 0.806 & 0.681 & 0.839 & 0.748 & 0.874 & 0.791 & 0.866 & 0.788 & 0.885 & 0.819 & 0.839 & 0.777 \\
\hline
0.1  & 0.734 & 0.549 & 0.794 & 0.655 & 0.818 & 0.7   & 0.821 & 0.703 & 0.772 & 0.665 & 0.854 & 0.784 & 0.877 & 0.809 & 0.883 & 0.807 \\
\hline
0.2  & 0.705 & 0.502 & 0.77  & 0.61  & 0.796 & 0.659 & 0.809 & 0.686 & 0.804 & 0.67  & 0.845 & 0.748 & 0.842 & 0.76  & 0.871 & 0.785 \\
\hline
0.4  & 0.656 & 0.431 & 0.725 & 0.533 & 0.753 & 0.579 & 0.793 & 0.653 & 0.81  & 0.686 & 0.816 & 0.697 & 0.785 & 0.645 & 0.726 & 0.608 \\
\hline
0.7  & 0.602 & 0.342 & 0.656 & 0.431 & 0.686 & 0.476 & 0.732 & 0.547 & 0.753 & 0.579 & 0.767 & 0.604 & 0.778 & 0.624 & 0.785 & 0.638 \\
\hline
1    & 0.582 & 0.304 & 0.61  & 0.358 & 0.635 & 0.397 & 0.678 & 0.463 & 0.698 & 0.492 & 0.716 & 0.519 & 0.729 & 0.542 & 0.737 & 0.554 \\
\hline
    \end{tabular}
}

\vspace{2\baselineskip}
\caption{Качество алгоритмов, обученных на данных с обработкой \textbf{Лемматизацией}}
\label{table:default_lemmatized_and_stemmed_dataset_comparision:lemm}
\centerline{
    \begin{tabular}{|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|}
    \hline

    \multirow{2}{*}{beta\textbackslash{}alpha} & \multicolumn{2}{c|}{0.1} &
    \multicolumn{2}{c|}{0.5} & \multicolumn{2}{c|}{1.0} & \multicolumn{2}{c|}{3.0} & 
    \multicolumn{2}{c|}{5} & \multicolumn{2}{c|}{7.5} & \multicolumn{2}{c|}{10} & 
    \multicolumn{2}{c|}{12} \\
    \cline{2-17}
        & Acc & F1 & Acc & F1 & Acc & F1 & Acc & F1 & Acc & F1 & Acc & F1 & Acc & F1 & Acc & F1\\
\hline
0.01 & 0.756& 0.586 & 0.822& 0.707 & 0.805 & 0.681 & 0.877 & 0.79  & 0.89  & 0.819 & 0.849 & 0.788 & 0.892& 0.827 & 0.827 & 0.767 \\
\hline
0.05 & 0.744& 0.564 & 0.813& 0.691 & 0.817 & 0.697 & 0.801 & 0.7   & 0.885 & 0.812 & 0.891 & 0.821 & 0.891& 0.826 & 0.892 & 0.828 \\
\hline
0.1  & 0.727& 0.531 & 0.799& 0.666 & 0.806 & 0.678 & 0.786 & 0.649 & 0.836 & 0.692 & 0.887 & 0.815 & 0.889& 0.821 & 0.892 & 0.824 \\
\hline
0.2  & 0.699& 0.471 & 0.774& 0.619 & 0.803 & 0.674 & 0.81  & 0.69  & 0.82  & 0.702 & 0.85  & 0.741 & 0.831& 0.751 & 0.872 & 0.8   \\
\hline
0.4  & 0.659& 0.367 & 0.718& 0.511 & 0.752 & 0.578 & 0.798 & 0.665 & 0.819 & 0.702 & 0.818 & 0.699 & 0.812& 0.686 & 0.809 & 0.69  \\
\hline
0.7  & 0.627& 0.282 & 0.659& 0.367 & 0.681 & 0.424 & 0.726 & 0.529 & 0.752 & 0.579 & 0.77  & 0.612 & 0.783& 0.635 & 0.791 & 0.65  \\
\hline
1    & 0.595& 0.267 & 0.632& 0.291 & 0.643 & 0.324 & 0.675 & 0.414 & 0.694 & 0.462 & 0.712 & 0.5   & 0.727& 0.532 & 0.736 & 0.551 \\
\hline
    \end{tabular}
}

\vspace{2\baselineskip}
\caption{Качество алгоритмов, обученных на данных с обработкой \textbf{Стеммингом}}
\label{table:default_lemmatized_and_stemmed_dataset_comparision:stem}
\centerline{
    \begin{tabular}{|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|}
    \hline
    \multirow{2}{*}{beta\textbackslash{}alpha} & \multicolumn{2}{c|}{0.1} &
    \multicolumn{2}{c|}{0.5} & \multicolumn{2}{c|}{1.0} & \multicolumn{2}{c|}{3.0} & 
    \multicolumn{2}{c|}{5} & \multicolumn{2}{c|}{7.5} & \multicolumn{2}{c|}{10} & 
    \multicolumn{2}{c|}{12} \\
    \cline{2-17}
        & Acc & F1 & Acc & F1 & Acc & F1 & Acc & F1 & Acc & F1 & Acc & F1 & Acc & F1 & Acc & F1\\
        
\hline
0.01 & 0.766 & 0.608 & 0.825 & 0.716 & 0.837 & 0.737 & 0.83  & 0.722 & 0.814 & 0.655 & 0.89  & 0.813 & 0.837 & 0.772 & 0.871 & 0.81  \\
\hline
0.05 & 0.756 & 0.592 & 0.816 & 0.7   & 0.836 & 0.736 & 0.844 & 0.748 & 0.822 & 0.701 & 0.871 & 0.8   & 0.851 & 0.786 & 0.873 & 0.81  \\
\hline
0.1  & 0.744 & 0.574 & 0.805 & 0.679 & 0.828 & 0.723 & 0.84  & 0.744 & 0.828 & 0.717 & 0.847 & 0.757 & 0.862 & 0.788 & 0.87  & 0.8   \\
\hline
0.2  & 0.719 & 0.542 & 0.782 & 0.637 & 0.808 & 0.685 & 0.836 & 0.736 & 0.844 & 0.751 & 0.836 & 0.739 & 0.825 & 0.709 & 0.837 & 0.733 \\
\hline
0.4  & 0.655 & 0.464 & 0.737 & 0.563 & 0.762 & 0.603 & 0.804 & 0.678 & 0.822 & 0.711 & 0.834 & 0.731 & 0.838 & 0.74  & 0.843 & 0.747 \\
\hline
0.7  & 0.587 & 0.379 & 0.655 & 0.464 & 0.691 & 0.509 & 0.744 & 0.573 & 0.763 & 0.604 & 0.778 & 0.631 & 0.789 & 0.651 & 0.798 & 0.665 \\
\hline
1    & 0.555 & 0.366 & 0.597 & 0.387 & 0.629 & 0.426 & 0.684 & 0.503 & 0.711 & 0.536 & 0.729 & 0.558 & 0.741 & 0.572 & 0.751 & 0.586 \\
\hline
    \end{tabular}
}
\end{sidewaystable}

    
\end{document}
